const logotext = "Seonghee Lee";
const meta = {
    title: "Seonghee Lee",
    description: "I'm Seonghee Lee a Master's student at Stanford studying Computer Science.",
};

const introdata = {
    title: "Seonghee Lee",
    animated: {
        first: "Human AI Interaction",
        second: "Applied Machine Learning",
    },
    description: "In the past, I was a Research Assistant at the KAIST Interaction Lab (KIXLAB) developing a Generative Agent for Programming Education. My research interests are at the intersection of Human-AI Interaction and applied Machine Learning." ,
    description_two:"  I am currently a first year Computer Science (MS) student at Stanford and I did my undergrad at Cornell studying Information Science. I have received grants and scholarships for my research like the Robert S Ann Morley Research Grant and the Gwanjeong Scholarship for my Master's Studies.",
    your_img_url: "",
};

const dataabout = {
    title: "Research Interests",
    aboutme: "My research is primarily focused on the development of AI tools for communities, specifically exploring the implementation of LLM agents with model-level interactions or user-centered evaluations. I aim to create tools that embrace social consciousness, beyond considerations of model precision and performance.",
};
const worktimeline = [{
        jobtitle: "Stanford University",
        where: "Computer Science (MS)",
        date: "Sep 2023 - June 2025",
    },
    {
        jobtitle: "Cornell University",
        where: "Information Science (BS)",
        date: "Sep 2019 - Dec 2022",
    },
];

// const skills = [{
//         name: "Python",
//         value: 90,
//     },
//     {
//         name: "Djano",
//         value: 85,
//     },
//     {
//         name: "Javascript",
//         value: 80,
//     },
//     {
//         name: "React",
//         value: 60,
//     },
//     {
//         name: "Jquery",
//         value: 85,
//     },
// ];

const services = [{
        title: "SDG AI Lab - Software Engineer",
        period:"March 2023 - May 2023",
        description: "Development of the Digital Technologies Radar : a Frontier Technology Radar for Disaster Risk Reduction (FTR4DRR), which allows for the systematic tracking and understanding of frontier technologies as they are developed. https://github.com/SDG-AI-Lab/Digital_Technologies_Radar",
    },
    {
        title: "Inspirit AI - AI/ML Instructor",
        period:"March 2020 - ",
        description: "Conducted lectures on Neural Networks, Computer Vision, Deep Learning, Reinforcement Learning and helped highschool students work on programming ML Models",
    },
    {
        title: "Cornell Data Science - Insights Team",
        period:"Janurary 2020 - December 2022 ",
        description: "Insights Team - Conducted and led Data Science/Machine Learning Projects, Conducted lectures on Neural Networks for Freshman Onboarding INFO 1998 ML lectures ",
    },
];

const awards = [{
    title: "Gwanjeong Educational Foundation Scholarship - Masters Degree",
    period:"Sep 2023 - June 2025",
},
{
    title: "ACM/IEEE Human Robot Interaction (HRI 2023) - Best Student Paper Award",
    period:"March 2022",
},
{
    title: "Robert S Ann Morley Research Grant - Cornell University",
    period:" December 2021 ",
},
];

const workexperience = [{
    title: "[Motional] Robotics Research Engineer",
    period:"Sep 2022 - Dec 2022",
    description: "Research on identification of Autonomous Vehicle Lane Change key parameters and metrics in dynamic road environments interacting with other agents. Published and first authored 2 papers to ACM/IEEE HRI 2023",
},
{
    title: "[Harvard Berkman Klein Center] Software Engineer",
    period:"May 2023 - August 2023",
    description: "Developed Software for dynamic text annotation and page navigation on H2O, an open-casebook platform (React, Django). Conducted Research on Digital Reading Interaction Software and published paper to ACM/IEEE CHI 2023",
},
{
    title: "[Cochl. AI] Software Engineer",
    period:"Nov 2020 - Feb 2021 ",
    description: "Integrated non-verbal sound recognition AI into Mercedes Benz User Interface. Full-stack development using React, Javascript, SocketIO, Docker. Developed and demonstrated a working prototype of Emotional Sound Recognition within Benz Cars to the Mercedes Benz Team - Presentation at Benz conference in Germany",
},
];

const researchexperience = [{
    title: "KIXLab (Prof. Juho Kim) - Generative Agents for Programming",
    period:"June 2023 - ",
    description: "Developed a LLM Teachable Agent (Algobo) for Programming Education. Developed prompting techniques for Knowledge State Configuration and conducted LLM Agent Evaluation on different knowledge states. Submitted to CHI 2024",
},
{
    title: "CMU Safe AI Lab - Multimodal ML Research",
    period:"Jan 2023 - March 2023 ",
    description: "Conducted lectures on Neural Networks, Computer Vision, Deep Learning, Reinforcement Learning and helped highschool students work on programming ML Models",
},
{
    title: "Stanford Empirical Security Research Group (ESRG)",
    period:"June 2023 - ",
    description: "Perceived Harm Research through an extension that collects user viewed comments on Reddit. Full Stack Development of website that processes user comments, labels toxicity scores and generates survey pairs. Parallel processing of comments, data mangagement and storage, web security. ",
},
];

const dataportfolio = [
    {
        img: "altCanvas",
        title: "AltCanvas: A Tile-Based Image Editor with Generative AI for Blind or Visually Impaired People",
        authors: "Seonghee Lee, Maho Kohga, Steve Landau, Sile O'Modhrain, Hari Subramonyam",
        conference: "ACM SIGACCESS Conference on Computers and Accessibility, ASSETS 2024",
        doi:"https://doi.org/10.48550/arXiv.2408.10240",
        video:"https://www.youtube.com/watch?v=tJUqjjwSxPs",
        project:"https://shljessie.github.io/AltCanvas/",
        code:"coming soon",
    },
    {
        img: "cs224s",
        title: "Beyond Scale: Analyzing ASR Model Performance in Code-Switching Data",
        authors: "Seonghee Lee, Yiling Zhao, Michela Marchini",
        conference: "CS 224S Speech Language Processing (A+)",
        doi:"https://drive.google.com/file/d/1iVEVgdgw4sbKr1InlFf43_tFV8i-9Oi0/view",
    }
    ,
    {
        img: "teachyou",
        title: "Teach AI How to Code: Using Large Language Models as Teachable Agents for Programming Education",
        authors: "Hyoungwook Jin, Seonghee Lee, Hyungyu Shin, Juho Kim",
        conference: "2024 19th ACM/IEEE International Conference on Human-Computer Interaction (CHI)",
        doi:"https://doi.org/10.1145/3613904.3642349",
        video:"https://www.youtube.com/watch?v=MEtcA6GjfAg",
        project:"https://jhw123.github.io/project/teachyou",
    }
    ,
    {
        img: "multi",
        title: "MultiSum: A Large Dataset for Multimodal Video Temporal Segmentation and Summarization",
        authors: "Jielin Qiu, Claire Jin, Seong hee Lee, Ding Zhao, 2023 18th ACM/IEEE International Conference on Machine Learning (ICML), 2023",
        link: "https://drive.google.com/file/d/12hRGbsry94zcJsU2V1_bVWFulYbyOi0c/view?usp=sharing",
    }
];

const projectportfolio = [
    {
        title: "DarakBooks - LLM based Book Recommendation",
        description: "Backend Development of LLM Based Book Recommendation API, User Book Club Groups API - Typescript, Nestjs, Swagger",
        github: "https://github.com/darakbooks-project/darakbooks-BE",
        website: "https://darakbooks.vercel.app/onboarding"
    },
    {
        title: "Perceived Harm Reddit - Stanford ESRG",
        description: "Fullstack Development of Reddit Survey through using a chrome extension to scrape user comments, analyze scores through Perspective and Generative survey questions. Parallel Processing, Serverside development Django",
        github: "https://github.com/shljessie/RedditSurvey",
        website: "http://reddit.esrg.stanford.edu/"
    },
    {
        title: "Mecerdez Benz Non-Verbal AI Interaction - Cochl.AI",
        description: "Full Stack development of Non-verbal AI Interaction prototype in Mercedes Benz Cars using Cochl Socket API",
        github: "https://github.com/shljessie/MBUX",
    },
    {
        title: "MyCourseIndex - Cornell Data Science",
        description: "an essential search engine for Cornell students and their courses with the initial goal to improve the Piazza search user experience. This search gathers all information from Piazza posts to Textbook and Notes Resources and returns valid results for the student to utilize",
        github: "https://github.com/oscarso2000/MyCourseIndex",
    },
    // {
    //     title: "IEUM Bridging Transportation and Humans",
    //     description: "Best Student Paper Award at Human Robot Interaction Conference (ACM/IEEE) HRI 2022",
    //     paper: "https://ieeexplore.ieee.org/abstract/document/9889531",
    // },
    {
        title: "Eternal Testimony",
        description: "As of Jun 2020, there are only 17 survivors of the Japanese military comfort women. We are initiating the '영원한 증언 Eternal Testimony' project, a novel way to preserve our history for all perpetuity in a vivid and memorable way.",
        website: "https://www.creative-computing.org/post/eternal-testimony-2018-2020",
    },
    {
        title: "The Last 100 meter Problem: Passenger Interaction in Autonomous Vehicles",
        description: "A Gestural Interaction for Passenger Interaction in Autonomous Vehicles",
        paper: "https://yw6524.wixsite.com/carat",
    },
    // {
    //     title: "Algorithmic Awareness on Youtube",
    //     description: "User Prototying to Explore User Awareness of Youtube Recommendations",
    //     paper: "http://127.0.0.1:4000/assets/youtube.pdf",
    // },
    // {
    //     title: "Remote Interaction with Embodied EyeTracking Robot",
    //     description: "We present an open-source, low cost telepresence robot that moves according to a remote user’s head movements and has a display that can be used to display a video of the remote user.",
    //     paper: "https://drive.google.com/file/d/19x9CiQBZJfIglFcGmhnYhgXXs3ZLQPIj/view",
    // },
];

const contactConfig = {
    YOUR_EMAIL: "shl1027@stanford.edu",
    YOUR_FONE: "-",
    description: "- ",
    // creat an emailjs.com account 
    // check out this tutorial https://www.emailjs.com/docs/examples/reactjs/
    YOUR_SERVICE_ID: "service_id",
    YOUR_TEMPLATE_ID: "template_id",
    YOUR_USER_ID: "user_id",
};

const socialprofils = {
    github: "https://github.com/shljessie",
    facebook: "https://facebook.com",
    scholar: "https://scholar.google.com/citations?user=POepUzkAAAAJ&hl=en",
    linkedin: "https://www.linkedin.com/in/seonghee-lee/",
    twitter: "https://twitter.com",
};
export {
    meta,
    dataabout,
    dataportfolio,
    researchexperience,
    workexperience,
    worktimeline,
    services,
    introdata,
    contactConfig,
    socialprofils,
    projectportfolio,
    logotext,
    awards,
};